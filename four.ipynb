{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127099c5-900d-49f3-b286-244e2c5168a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64cf9ff-e1ac-4bc7-b256-09da91d713bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = []\n",
    "directory = \"Dataset/Q1\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".rtf\"):\n",
    "        with open(os.path.join(directory, filename), \"rb\") as file:\n",
    "            rtf_text = file.read().decode(\"utf-8\")\n",
    "            text = rtf_to_text(rtf_text)\n",
    "            text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "            text = re.sub(r'\\s+',' ',text)\n",
    "            text = re.sub(r'\\d+',' ',text)\n",
    "            text = re.sub(r'\\s+',' ',text)\n",
    "            text = text.lower()\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            words = [word for word in tokens if word.isalpha()]\n",
    "            words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "            cleaned_text = \" \".join(words)\n",
    "\n",
    "            tagged_data.append(TaggedDocument(words=cleaned_text.split(), tags=[str(len(tagged_data))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312c12c2-478a-42c7-aae0-d5d120469abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=10, window=5, min_count=1, dm=0, epochs=10)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df004c15-7dfc-4059-9010-ca4344207617",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_vectors = []\n",
    "for vector in tagged_data:\n",
    "    tokenized_doc = vector.words\n",
    "    doc_vec = model.infer_vector(tokenized_doc)\n",
    "    inferred_vectors.append(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca329c60-af2a-4ca5-94fd-17e148da3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = linkage(inferred_vectors, method='ward', metric='euclidean')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linked, orientation='bottom', distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Document Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49425766-a989-43e5-af25-3fbb0f66676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "[5, 23, 54, 63, 84, 85, 91, 95, 100]\n",
      "Cluster 1:\n",
      "[7, 32, 33, 34, 36, 37, 38, 39, 41, 42, 49, 50, 52, 55, 56, 58, 59, 61, 62, 66, 67, 69, 70, 74, 75, 76, 77, 79, 80, 81, 82, 83]\n",
      "Cluster 2:\n",
      "[10, 11, 12, 13, 14, 90, 103, 104]\n",
      "Cluster 3:\n",
      "[18, 22, 24, 25]\n",
      "Cluster 4:\n",
      "[1, 28, 30]\n",
      "Cluster 5:\n",
      "[29, 35, 51, 57, 73]\n",
      "Cluster 6:\n",
      "[43, 47, 53, 98]\n",
      "Cluster 7:\n",
      "[48, 60, 99]\n",
      "Cluster 8:\n",
      "[15, 92, 94, 101]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=0.0999, min_samples=3)\n",
    "dbscan.fit(inferred_vectors)\n",
    "\n",
    "cluster_labels = dbscan.labels_\n",
    "n_clusters_ = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "\n",
    "for cluster_id in range(n_clusters_):\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
    "    print(cluster_indices)\n",
    "    \n",
    "outlier_count = 0\n",
    "for n in cluster_labels:\n",
    "    if(n==-1):\n",
    "        outlier_count = outlier_count+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "484e206c-859c-416f-8b29-ddcae97a0cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9cf00-f788-460b-9ce9-d5527550a785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
